{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Poisson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DR8NggrA5fTxl81usyu85G8mdzu4VYTr",
      "authorship_tag": "ABX9TyO/0nmU9g0qZSAHbjqZPD+w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamtung1997/Solving_PDEs_Deep_learning/blob/main/1_Poisson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmGzlShRQ-3j"
      },
      "source": [
        "# SETUP\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import itertools\n",
        "pi = math.pi"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alwi7ztmxQOT"
      },
      "source": [
        "# MODEL\n",
        "inputs = keras.Input(shape=(2,), name='points')\n",
        "hidden_1 = layers.Dense(64, activation='sigmoid', name='hidden_1')(inputs)\n",
        "hidden_2 = layers.Dense(64, activation='sigmoid', name='hidden_2')(hidden_1)\n",
        "hidden_3 = layers.Dense(64, activation='sigmoid', name='hidden_3')(hidden_2)\n",
        "outputs = layers.Dense(1, activation=tf.math.square, name=\"fx\")(hidden_3)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='poisson')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYfmTeVUduG"
      },
      "source": [
        "# DATA\n",
        "import itertools\n",
        "\n",
        "n = 30                      # number of points in a border\n",
        "c = np.linspace(0, 1, n)    # coordinates from 0 to 1 with uniform distribution\n",
        "P_in, P_border = [],[]\n",
        "for i, j in itertools.product(range(n), range(n)):\n",
        "    p = [c[i], c[j]]\n",
        "    if(i == 0 or i == n-1 or j == 0 or j == n-1):\n",
        "        P_border.append(p)\n",
        "    else:\n",
        "        P_in.append(p)\n",
        "\n",
        "# upsampling P_border that its size is equal to P_in\n",
        "for i in range(len(P_in)-len(P_border)):\n",
        "    j = i%(len(P_in))\n",
        "    P_border.append(P_border[j])\n",
        "\n",
        "# set batch_size and shuffle_size\n",
        "batch_size = int(len(P_border)/392)\n",
        "bs = int(len(P_border))\n",
        "\n",
        "# convert numpy array, P_in and P_border to Tensorflow Dataset\n",
        "P_in = tf.convert_to_tensor(P_in, dtype=tf.float32)\n",
        "P_border = tf.convert_to_tensor(P_border, dtype=tf.float32)\n",
        "\n",
        "P_in = tf.data.Dataset.from_tensor_slices((P_in))\n",
        "P_in = P_in.shuffle(buffer_size=bs).batch(batch_size)\n",
        "\n",
        "P_border = tf.data.Dataset.from_tensor_slices((P_border))\n",
        "P_border = P_border.shuffle(buffer_size=bs).batch(batch_size)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVaW8j-64tz4"
      },
      "source": [
        "# CHOOSE OPTIMIZER\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK9zspI6pczi"
      },
      "source": [
        "# TRAIN FUNCTION\n",
        "@tf.function\n",
        "def train_step(P_in, P_border):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_in, loss_border = [0], [0]\n",
        "        # interior loss\n",
        "        for i in range(P_in.shape[0]):\n",
        "            v = tf.reshape(P_in[i], shape=(1,2))\n",
        "            tape.watch(v)\n",
        "            model_vals = model(v)\n",
        "\n",
        "            # calculating u_xx and u_yy\n",
        "            u_x_y = tape.gradient(model_vals, v)\n",
        "            u_xx = tape.gradient(u_x_y[0][0], v)[0][0]\n",
        "            u_yy = tape.gradient(u_x_y[0][1], v)[0][1]\n",
        "\n",
        "            # calculating f(x,y)\n",
        "            f = -2*pi*pi* tf.math.sin(pi*v[0][0]) * tf.math.sin(pi*v[0][1])\n",
        "\n",
        "            # calculating loss_in\n",
        "            loss_in += tf.math.square(u_xx + u_yy - f)\n",
        "\n",
        "        # boundary loss\n",
        "        for j in range(P_border.shape[0]):\n",
        "            v = tf.reshape(P_border[j], shape=(1,2))\n",
        "            loss_border += tf.math.square(model(v))\n",
        "        \n",
        "        # loss function\n",
        "        batch_loss = loss_in + loss_border\n",
        "    \n",
        "    # update weights\n",
        "    grads = tape.gradient(batch_loss, model.trainable_weights)          # gradient of loss function with respect to w\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))      # update w\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQ_WTXlpegx",
        "outputId": "3653f1b3-4dc8-4d09-9b67-ae3ae7ac3447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# TRAIN\n",
        "epochs = 2000\n",
        "losses = []\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs+1):\n",
        "\n",
        "    optimizer.learning_rate.assign(1/(10**(int(epoch/400) + 2)))\n",
        "\n",
        "    loss = 0\n",
        "    for (P_in_batch,P_border_batch) in itertools.zip_longest(P_in,P_border):\n",
        "        batch_loss = train_step(P_in_batch, P_border_batch)\n",
        "        loss += batch_loss\n",
        "    losses.append(loss.numpy())\n",
        "    if(epoch%100 == 0):\n",
        "        print(\"[%4s] Training loss: %10f \\t learning_rate: %f\" % (epoch, float(loss), optimizer.learning_rate.numpy()))\n",
        "\n",
        "print(\"Total time: %.2f minutes\" % ((time.time() - start_time)/60))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "[  0] Training loss: 40404.644531 \t learning_rate: 0.010000\n",
            "[100] Training loss: 350.609192 \t learning_rate: 0.010000\n",
            "[200] Training loss: 243.876877 \t learning_rate: 0.010000\n",
            "[300] Training loss: 163.018570 \t learning_rate: 0.010000\n",
            "[400] Training loss:  46.793743 \t learning_rate: 0.001000\n",
            "[500] Training loss:  22.267120 \t learning_rate: 0.001000\n",
            "[600] Training loss:  17.741863 \t learning_rate: 0.001000\n",
            "[700] Training loss:  14.452739 \t learning_rate: 0.001000\n",
            "[800] Training loss:   8.619843 \t learning_rate: 0.000100\n",
            "[900] Training loss:   7.950186 \t learning_rate: 0.000100\n",
            "[1000] Training loss:   7.699492 \t learning_rate: 0.000100\n",
            "[1100] Training loss:   7.479762 \t learning_rate: 0.000100\n",
            "[1200] Training loss:   7.052985 \t learning_rate: 0.000010\n",
            "[1300] Training loss:   6.942818 \t learning_rate: 0.000010\n",
            "[1400] Training loss:   6.925884 \t learning_rate: 0.000010\n",
            "[1500] Training loss:   6.909665 \t learning_rate: 0.000010\n",
            "[1600] Training loss:   6.845490 \t learning_rate: 0.000001\n",
            "[1700] Training loss:   6.842420 \t learning_rate: 0.000001\n",
            "[1800] Training loss:   6.839942 \t learning_rate: 0.000001\n",
            "[1900] Training loss:   6.837971 \t learning_rate: 0.000001\n",
            "[2000] Training loss:   6.831146 \t learning_rate: 0.000000\n",
            "Total time: 25.48 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8tx1ESm9Zm1",
        "outputId": "88fd3b60-e4c5-4116-8cb3-9d8e8abc474a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "z = tf.convert_to_tensor([[0.0, 0.0]])\n",
        "print(\"f(0.0, 0.0) \\t = %.2f\" % model(z).numpy()[0][0])\n",
        "z = tf.convert_to_tensor([[0.1, 0.1]])\n",
        "print(\"f(0.1, 0.1) \\t = %.2f\" % model(z).numpy()[0][0])\n",
        "z = tf.convert_to_tensor([[0.2, 0.2]])\n",
        "print(\"f(0.2, 0.2) \\t = %.2f\" % model(z).numpy()[0][0])\n",
        "z = tf.convert_to_tensor([[0.3, 0.3]])\n",
        "print(\"f(0.3, 0.3) \\t = %.2f\" % model(z).numpy()[0][0])\n",
        "z = tf.convert_to_tensor([[0.4, 0.4]])\n",
        "print(\"f(0.4, 0.4) \\t = %.2f\" % model(z).numpy()[0][0])\n",
        "z = tf.convert_to_tensor([[0.5, 0.5]])\n",
        "print(\"f(0.5, 0.5) \\t = %.2f\" % model(z).numpy()[0][0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f(0.0, 0.0) \t = 0.04\n",
            "f(0.1, 0.1) \t = 0.15\n",
            "f(0.2, 0.2) \t = 0.41\n",
            "f(0.3, 0.3) \t = 0.73\n",
            "f(0.4, 0.4) \t = 0.99\n",
            "f(0.5, 0.5) \t = 1.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPVBulQbHw6Q"
      },
      "source": [
        "# model.save(\"/content/drive/My Drive/Colab Notebooks/Keras/Solving PDEs/1. Poisson\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5AFmoSvIBjI"
      },
      "source": [
        "model1 = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/Keras/Solving PDEs/1. Poisson\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfx0KyhUIL-S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}