{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Stokes (inverse).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_3cVkHY51iAc6AIsuKJpF7wuNEGE_AMT",
      "authorship_tag": "ABX9TyMJ3MOY9GRR6rFGIJxcvSCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamtung1997/Solving_PDEs_Deep_learning/blob/main/3_Stokes_(inverse).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_TrNBg-PzPk"
      },
      "source": [
        "# SETUP\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import itertools\n",
        "import os\n",
        "import logging\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.constraints import Constraint\n",
        "import keras.backend as K\n",
        "\n",
        "# set numpy decimal\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "\n",
        "# number pi\n",
        "pi = math.pi\n",
        "\n",
        "# STOP WARNING\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
        "\n",
        "# random_seed\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB3QsCJUP-lK"
      },
      "source": [
        "# DATA\n",
        "# load the dataset\n",
        "with open('/content/drive/My Drive/Colab Notebooks/Keras/Solving PDEs/3. Stokes (Inverse)/output_data (Neural).csv', 'r', encoding='utf-8-sig') as f: \n",
        "    data = np.genfromtxt(f, dtype=float, delimiter=',')\n",
        "\n",
        "# convert numpy array, P_in and P_border to Tensorflow Dataset\n",
        "xy = tf.convert_to_tensor(data[:, 0:2], dtype=tf.float32)\n",
        "u_v_p = tf.convert_to_tensor(data[:, 2:5], dtype=tf.float32)\n",
        "\n",
        "dat = tf.data.Dataset.from_tensor_slices((xy, u_v_p))\n",
        "\n",
        "batch_size = 1\n",
        "bs = int(len(data))\n",
        "# bs = 1\n",
        "\n",
        "dat = dat.shuffle(buffer_size=bs).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t86rPHgCy_Xm"
      },
      "source": [
        "# for e in dat:\n",
        "#     print(e[0].numpy()[0], e[1].numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZC3g_XiTCh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74441ba8-9b77-4cd5-e7d3-f6d0913514fd"
      },
      "source": [
        "print(\"number of data: \", dat.cardinality().numpy()*batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of data:  5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ndp5YgOWZko"
      },
      "source": [
        "# Set condition for weight 'nu'\n",
        "class Between(Constraint):\n",
        "    def __init__(self, min_value, max_value):\n",
        "        self.min_value = min_value\n",
        "        self.max_value = max_value\n",
        "\n",
        "    def __call__(self, nu):        \n",
        "        return K.clip(nu, self.min_value, self.max_value)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'min_value': self.min_value, 'max_value': self.max_value}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd-Byz_0XLAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6701d630-08a3-49fa-c9b5-76e6d3e266e7"
      },
      "source": [
        "# MODEL\n",
        "nn = 64\n",
        "ini = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)\n",
        "\n",
        "inputs = keras.Input(shape=(2,), name='points')\n",
        "hidden_1 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_1')(inputs)\n",
        "hidden_2 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_2')(hidden_1)\n",
        "hidden_3 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_3')(hidden_2)\n",
        "# hidden_4 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_4')(hidden_3)\n",
        "# hidden_5 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_5')(hidden_4)\n",
        "# hidden_6 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_6')(hidden_5)\n",
        "# hidden_7 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_7')(hidden_6)\n",
        "# hidden_8 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_8')(hidden_7)\n",
        "# hidden_9 = layers.Dense(nn, activation='tanh', kernel_initializer=ini, name='hidden_9')(hidden_8)\n",
        "outputs = layers.Dense(3, activation='linear', kernel_initializer=ini, name=\"u_v_p\")(hidden_3)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='stokes')\n",
        "model.add_weight(name=\"nu\", shape=(1,1), dtype=tf.float32, trainable=True, initializer=ini, constraint=Between(0, 100))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"stokes\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "points (InputLayer)          [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "hidden_1 (Dense)             (None, 64)                192       \n",
            "_________________________________________________________________\n",
            "hidden_2 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "hidden_3 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "u_v_p (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 8,708\n",
            "Trainable params: 8,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odWrCv8IXAFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf4ed9c-35d1-43b4-e37c-e7dcd926930f"
      },
      "source": [
        "model.weights[len(model.weights) - 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'nu:0' shape=(1, 1) dtype=float32, numpy=array([[0.006]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXHqpgdDd4x1"
      },
      "source": [
        "# CHOOSE OPTIMIZER\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TH3O-_8DVoW"
      },
      "source": [
        "# TRAIN FUNCTION\n",
        "@tf.function\n",
        "def train_step(dat_batch):\n",
        "    P = dat_batch[0]\n",
        "    uvp = dat_batch[1]\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        batch_loss = 0\n",
        "\n",
        "        # loss\n",
        "        for i in range(P.shape[0]):\n",
        "            z = tf.reshape(P[i], shape=(1,2))\n",
        "            tape.watch(z)\n",
        "            model_vals = model(z)\n",
        "\n",
        "            # calculating u_xx, u_yy, v_xx, v_yy, p_x, p_y\n",
        "            u = model_vals[0][0]\n",
        "            v = model_vals[0][1]\n",
        "            p = model_vals[0][2]\n",
        "\n",
        "            u_x = tape.gradient(u, z)[0][0]\n",
        "            u_xx = tape.gradient(u_x, z)[0][0]\n",
        "            u_y = tape.gradient(u, z)[0][1]\n",
        "            u_yy = tape.gradient(u_y, z)[0][1]\n",
        "            \n",
        "            v_x = tape.gradient(v, z)[0][0]\n",
        "            v_xx = tape.gradient(v_x, z)[0][0]\n",
        "            v_y = tape.gradient(v, z)[0][1]\n",
        "            v_yy = tape.gradient(v_y, z)[0][1]\n",
        "\n",
        "            p_x = tape.gradient(p, z)[0][0]\n",
        "            p_y = tape.gradient(p, z)[0][1]\n",
        "\n",
        "            # calculating loss\n",
        "            nu = model.weights[len(model.weights) - 1]\n",
        "            loss1 = tf.math.square(nu*(u_xx + u_yy) - p_x)\n",
        "            loss2 = tf.math.square(nu*(v_xx + v_yy) - p_y)\n",
        "            loss3 = tf.math.square(u_x + v_y)\n",
        "            loss4 = tf.math.square(u - uvp[0][0]) + tf.math.square(v - uvp[0][1]) + tf.math.square(p - uvp[0][2])\n",
        "            batch_loss += loss1 + loss2 + loss3 + loss4\n",
        "    \n",
        "    # update weights\n",
        "    grads = tape.gradient(batch_loss, model.trainable_weights)          # gradient of loss function with respect to w\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))      # update w\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws54Yks7Id-H"
      },
      "source": [
        "# TRAIN\n",
        "losses = []\n",
        "def train(epochs, learning_rate):\n",
        "    start_time = time.time()\n",
        "    optimizer.learning_rate.assign(learning_rate)\n",
        "    for epoch in range(epochs+1):\n",
        "        loss = 0\n",
        "        for dat_batch in dat:\n",
        "            batch_loss = train_step(dat_batch)\n",
        "            loss += batch_loss\n",
        "        losses.append(loss.numpy())\n",
        "\n",
        "        if(epoch%5 == 0):\n",
        "            print(\"[%3s] Training loss: %15.3f \\t nu = %.5f\" % (epoch, float(loss), model.weights[len(model.weights) - 1]))\n",
        "\n",
        "    print(\"Batch time: %.2f minutes\" % ((time.time() - start_time)/60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlVeCMowT1FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c54d97b-f32b-4d0a-fe1f-e08bbf80285c"
      },
      "source": [
        "lr = 1e-3\n",
        "ite = 3\n",
        "start_time = time.time()\n",
        "for i in range(ite):\n",
        "    print(\"Iteration:\", i, \"\\t lr:\", lr)\n",
        "    train(200, lr)\n",
        "    lr = lr/10\n",
        "    print()\n",
        "print(\"Total time: %.5f minutes\" % ((time.time() - start_time)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0 \t lr: 0.001\n",
            "[  0] Training loss:       22354.092 \t nu = 2.22902\n",
            "[  5] Training loss:        2372.718 \t nu = 2.20956\n",
            "[ 10] Training loss:        1655.268 \t nu = 2.21599\n",
            "[ 15] Training loss:        1240.931 \t nu = 2.19952\n",
            "[ 20] Training loss:        1103.377 \t nu = 2.11379\n",
            "[ 25] Training loss:         876.074 \t nu = 1.99950\n",
            "[ 30] Training loss:         810.255 \t nu = 1.87947\n",
            "[ 35] Training loss:         780.255 \t nu = 1.76284\n",
            "[ 40] Training loss:         779.626 \t nu = 1.64233\n",
            "[ 45] Training loss:         670.041 \t nu = 1.53885\n",
            "[ 50] Training loss:         639.197 \t nu = 1.44285\n",
            "[ 55] Training loss:         631.475 \t nu = 1.35991\n",
            "[ 60] Training loss:         551.741 \t nu = 1.28777\n",
            "[ 65] Training loss:         520.187 \t nu = 1.22093\n",
            "[ 70] Training loss:         534.075 \t nu = 1.16735\n",
            "[ 75] Training loss:         486.216 \t nu = 1.12585\n",
            "[ 80] Training loss:         449.208 \t nu = 1.09618\n",
            "[ 85] Training loss:         451.854 \t nu = 1.06933\n",
            "[ 90] Training loss:         470.865 \t nu = 1.04824\n",
            "[ 95] Training loss:         491.995 \t nu = 1.03311\n",
            "[100] Training loss:         453.236 \t nu = 1.02086\n",
            "[105] Training loss:         432.275 \t nu = 1.01123\n",
            "[110] Training loss:         409.010 \t nu = 1.00484\n",
            "[115] Training loss:         417.794 \t nu = 0.99522\n",
            "[120] Training loss:         433.594 \t nu = 0.99114\n",
            "[125] Training loss:         363.799 \t nu = 0.98416\n",
            "[130] Training loss:         349.097 \t nu = 0.98138\n",
            "[135] Training loss:         357.258 \t nu = 0.97545\n",
            "[140] Training loss:         365.262 \t nu = 0.97109\n",
            "[145] Training loss:         397.868 \t nu = 0.96984\n",
            "[150] Training loss:         308.260 \t nu = 0.96634\n",
            "[155] Training loss:         371.237 \t nu = 0.96592\n",
            "[160] Training loss:         312.289 \t nu = 0.96431\n",
            "[165] Training loss:         341.156 \t nu = 0.96707\n",
            "[170] Training loss:         373.752 \t nu = 0.96285\n",
            "[175] Training loss:         279.185 \t nu = 0.96227\n",
            "[180] Training loss:         331.780 \t nu = 0.96052\n",
            "[185] Training loss:         376.641 \t nu = 0.96068\n",
            "[190] Training loss:         319.466 \t nu = 0.96165\n",
            "[195] Training loss:         306.542 \t nu = 0.96063\n",
            "[200] Training loss:         302.660 \t nu = 0.96121\n",
            "Batch time: 28.21 minutes\n",
            "\n",
            "Iteration: 1 \t lr: 0.0001\n",
            "[  0] Training loss:          47.104 \t nu = 0.96147\n",
            "[  5] Training loss:          29.064 \t nu = 0.97042\n",
            "[ 10] Training loss:          23.741 \t nu = 0.98038\n",
            "[ 15] Training loss:          20.843 \t nu = 0.98751\n",
            "[ 20] Training loss:          18.003 \t nu = 0.99341\n",
            "[ 25] Training loss:          17.151 \t nu = 0.99805\n",
            "[ 30] Training loss:          16.145 \t nu = 1.00129\n",
            "[ 35] Training loss:          15.549 \t nu = 1.00495\n",
            "[ 40] Training loss:          14.982 \t nu = 1.00724\n",
            "[ 45] Training loss:          13.612 \t nu = 1.00968\n",
            "[ 50] Training loss:          13.165 \t nu = 1.01120\n",
            "[ 55] Training loss:          13.482 \t nu = 1.01249\n",
            "[ 60] Training loss:          13.167 \t nu = 1.01372\n",
            "[ 65] Training loss:          12.908 \t nu = 1.01496\n",
            "[ 70] Training loss:          12.402 \t nu = 1.01494\n",
            "[ 75] Training loss:          12.188 \t nu = 1.01517\n",
            "[ 80] Training loss:          12.329 \t nu = 1.01583\n",
            "[ 85] Training loss:          11.732 \t nu = 1.01568\n",
            "[ 90] Training loss:          11.221 \t nu = 1.01612\n",
            "[ 95] Training loss:          11.047 \t nu = 1.01640\n",
            "[100] Training loss:          11.435 \t nu = 1.01636\n",
            "[105] Training loss:          11.231 \t nu = 1.01621\n",
            "[110] Training loss:          11.169 \t nu = 1.01623\n",
            "[115] Training loss:          10.666 \t nu = 1.01682\n",
            "[120] Training loss:          10.613 \t nu = 1.01649\n",
            "[125] Training loss:          10.889 \t nu = 1.01642\n",
            "[130] Training loss:          10.201 \t nu = 1.01635\n",
            "[135] Training loss:          10.927 \t nu = 1.01629\n",
            "[140] Training loss:          12.012 \t nu = 1.01636\n",
            "[145] Training loss:           9.930 \t nu = 1.01598\n",
            "[150] Training loss:           9.664 \t nu = 1.01584\n",
            "[155] Training loss:          10.900 \t nu = 1.01605\n",
            "[160] Training loss:          10.620 \t nu = 1.01608\n",
            "[165] Training loss:          10.165 \t nu = 1.01599\n",
            "[170] Training loss:          10.009 \t nu = 1.01593\n",
            "[175] Training loss:           9.702 \t nu = 1.01563\n",
            "[180] Training loss:           9.696 \t nu = 1.01558\n",
            "[185] Training loss:           9.644 \t nu = 1.01532\n",
            "[190] Training loss:           9.919 \t nu = 1.01556\n",
            "[195] Training loss:           9.149 \t nu = 1.01577\n",
            "[200] Training loss:           9.254 \t nu = 1.01548\n",
            "Batch time: 28.31 minutes\n",
            "\n",
            "Iteration: 2 \t lr: 1e-05\n",
            "[  0] Training loss:           3.826 \t nu = 1.01549\n",
            "[  5] Training loss:           3.834 \t nu = 1.01543\n",
            "[ 10] Training loss:           3.803 \t nu = 1.01544\n",
            "[ 15] Training loss:           3.789 \t nu = 1.01559\n",
            "[ 20] Training loss:           3.795 \t nu = 1.01557\n",
            "[ 25] Training loss:           3.742 \t nu = 1.01563\n",
            "[ 30] Training loss:           3.750 \t nu = 1.01571\n",
            "[ 35] Training loss:           3.752 \t nu = 1.01577\n",
            "[ 40] Training loss:           3.754 \t nu = 1.01584\n",
            "[ 45] Training loss:           3.745 \t nu = 1.01599\n",
            "[ 50] Training loss:           3.693 \t nu = 1.01602\n",
            "[ 55] Training loss:           3.684 \t nu = 1.01604\n",
            "[ 60] Training loss:           3.679 \t nu = 1.01605\n",
            "[ 65] Training loss:           3.654 \t nu = 1.01614\n",
            "[ 70] Training loss:           3.685 \t nu = 1.01620\n",
            "[ 75] Training loss:           3.653 \t nu = 1.01630\n",
            "[ 80] Training loss:           3.663 \t nu = 1.01622\n",
            "[ 85] Training loss:           3.680 \t nu = 1.01632\n",
            "[ 90] Training loss:           3.638 \t nu = 1.01629\n",
            "[ 95] Training loss:           3.634 \t nu = 1.01637\n",
            "[100] Training loss:           3.608 \t nu = 1.01648\n",
            "[105] Training loss:           3.591 \t nu = 1.01642\n",
            "[110] Training loss:           3.599 \t nu = 1.01647\n",
            "[115] Training loss:           3.589 \t nu = 1.01654\n",
            "[120] Training loss:           3.565 \t nu = 1.01648\n",
            "[125] Training loss:           3.581 \t nu = 1.01658\n",
            "[130] Training loss:           3.559 \t nu = 1.01659\n",
            "[135] Training loss:           3.579 \t nu = 1.01661\n",
            "[140] Training loss:           3.542 \t nu = 1.01662\n",
            "[145] Training loss:           3.528 \t nu = 1.01663\n",
            "[150] Training loss:           3.543 \t nu = 1.01657\n",
            "[155] Training loss:           3.517 \t nu = 1.01665\n",
            "[160] Training loss:           3.525 \t nu = 1.01669\n",
            "[165] Training loss:           3.493 \t nu = 1.01662\n",
            "[170] Training loss:           3.486 \t nu = 1.01665\n",
            "[175] Training loss:           3.468 \t nu = 1.01672\n",
            "[180] Training loss:           3.484 \t nu = 1.01662\n",
            "[185] Training loss:           3.457 \t nu = 1.01666\n",
            "[190] Training loss:           3.473 \t nu = 1.01673\n",
            "[195] Training loss:           3.458 \t nu = 1.01671\n",
            "[200] Training loss:           3.468 \t nu = 1.01676\n",
            "Batch time: 31.56 minutes\n",
            "\n",
            "Total time: 88.07805 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMDKbYB28X5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b742ad6-e1ac-4711-d6c1-ce7cd6ccb419"
      },
      "source": [
        "z = tf.convert_to_tensor([[0.5, 0.0]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.1]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.2]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.3]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.4]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.5]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.6]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.7]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.8]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 0.9]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])\n",
        "z = tf.convert_to_tensor([[0.5, 1.0]])\n",
        "print(\"u(\",z.numpy()[0][0], z.numpy()[0][1],\") \\t = %s\" % model(z).numpy()[0][0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u( 0.5 0.0 ) \t = [-0.015 0.005]\n",
            "u( 0.5 0.1 ) \t = [-0.045 0.003]\n",
            "u( 0.5 0.2 ) \t = [-0.083 0.004]\n",
            "u( 0.5 0.3 ) \t = [-0.121 0.004]\n",
            "u( 0.5 0.4 ) \t = [-0.149 0.005]\n",
            "u( 0.5 0.5 ) \t = [-0.151 0.004]\n",
            "u( 0.5 0.6 ) \t = [-0.108 0.002]\n",
            "u( 0.5 0.7 ) \t = [0.006 0.000]\n",
            "u( 0.5 0.8 ) \t = [0.219 -0.001]\n",
            "u( 0.5 0.9 ) \t = [0.559 -0.002]\n",
            "u( 0.5 1.0 ) \t = [1.046 -0.004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRH-jfefmW-n"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/Keras/Solving PDEs/3. Stokes (Inverse)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkb5P0hCmgdI"
      },
      "source": [
        "model1 = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/Keras/Solving PDEs/3. Stokes (Inverse)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}